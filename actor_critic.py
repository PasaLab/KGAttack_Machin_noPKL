import torch
import torch.nn as nn
import torch.nn.functional as F


class ActorB(nn.Module):
    def __init__(self, encodingNet, args):
        super(ActorB, self).__init__()
        self.args = args
        self.encoding = encodingNet
        self.rnn = nn.GRU(args.gcn_hidden, args.gru_hidden, args.gru_layer, batch_first=True)
        self.fc1 = nn.Linear(args.gru_hidden, args.actor_hidden)
        self.fc2 = nn.Linear(args.actor_hidden+args.gcn_hidden, args.actor_hidden)   #hidden_dim + emb_size
        self.fc3 = nn.Linear(args.actor_hidden,1)
    
    def unpad(self, state):
        if len(state.shape) == 1:
            state = state.reshape(-1, state.shape[0])
        for i in range(state.shape[1]):
            if state[0][i] == -1:
                state = state[:,:i]
                break
        return state
    def forward(self, some_state, valid_actions, item_action=None):
        """
        :param x: encode state history [N*L*D]; y: action embedding [N*K*E],
            
            N: batch size, L: seq length, D: embedding size, K: action set length
        :return: action score [N*K]
        """
        # state, candi=  some_state['some_state'], some_state['valid_actions']
        # # print('state', state)
        state = some_state.cpu().numpy()
        # # print('state', state)
        candi = valid_actions.cpu().numpy()
        
        # unppad the state
        # state = self.unpad(state)
        # # print('state', state)
        # # print('state shape',state.shape)
        x = self.encoding(state[:,1:])# [N*L*E]
        y = self.encoding.embedding(torch.LongTensor(candi).to(self.args.device)) # [N*C*E]
        out, h = self.rnn(x)
        h = h.permute(1,0,2) #[N*1*D]
        # test = x[torch.arange(x.shape[0]),a1,:].unsqueeze(1)
        # # print(x[0,a1[0],:])
        # # print(test[0])
        x = F.relu(self.fc1(h))
        x = x.repeat(1,y.shape[1],1) # [N*K*D]
        state_cat_action = torch.cat((x,y),dim=2)
        action_logits = self.fc3(F.relu(self.fc2(state_cat_action))).squeeze(dim=2) #[N*K]
        a_prob = F.softmax(action_logits, dim=1)
        dist = torch.distributions.Categorical(a_prob)
        a_idx = item_action if item_action is not None else dist.sample()
        ## print('a_idx',a_idx.shape) (93,1)
        ## print('a_idx.flatten',a_idx.flatten()) (93,)
        act_entropy = dist.entropy()
        act_log_prob = dist.log_prob(a_idx.flatten())
        ## print('act_entropy',act_entropy.shape) #(93,)
        ## print('act_log_prob',act_log_prob.shape) #(93,)
        # assert act_log_prob.shape == a_idx.shape
        return a_idx, act_log_prob, act_entropy

# Hierarchical action space
# todo:
# 1. add net in init and new action in argument
# 2. generate the second action ok 
# 3. use mask [batch, episode_length] generated by env and add mask in argument ok
# 4. mask should store in state ok 
# 5. return concat[action] ok 
class ActorH(nn.Module):
    def __init__(self, encodingNet, args):
        super(ActorH, self).__init__()
        self.args = args
        self.encoding = encodingNet
        self.rnn = nn.GRU(args.gcn_hidden, args.gru_hidden, args.gru_layer, batch_first=True)
        self.fc1 = nn.Linear(args.gru_hidden, args.actor_hidden)
        self.fc2 = nn.Linear(args.actor_hidden+args.gcn_hidden, args.actor_hidden)   #hidden_dim + emb_size
        self.fc3 = nn.Linear(args.actor_hidden,1)
        self.fc4 = nn.Linear(args.actor_hidden,args.episode_length)
    def unpad(self, state):
        if len(state.shape) == 1:
            state = state.reshape(-1, state.shape[0])
        for i in range(state.shape[1]):
            if state[0][i] == -1:
                state = state[:,:i]
                break
        return state
    
    def forward(self, some_state, valid_actions, pivot_mask, item_action=None, pivot_action = None):
        """
        :param x: encode state history [N*L*D]; y: action embedding [N*K*E],
            
            N: batch size, L: seq length, D: embedding size, K: action set length
        :return: action score [N*K]
        """
        # state, candi=  some_state['some_state'], some_state['valid_actions']
        # # print('state', state)
        some_state = some_state.cpu().numpy() # (batch_size, args.epi_len+1)
        valid_actions = valid_actions.cpu().numpy() # (batch_size, args.action_size)
        pivot_mask = pivot_mask.cpu().numpy() # (batch_size, epi_len)
        assert pivot_mask.shape[0] == some_state.shape[0] == valid_actions.shape[0] 
        
        # unppad the state
        # state = self.unpad(state)
        # # print('state', state)
        # # print('state shape',state.shape)
        x = self.encoding(some_state[:,1:])# [N*L*E]
        y = self.encoding.embedding(torch.LongTensor(valid_actions).to(self.args.device)) # [N*C*E]
        out, h = self.rnn(x)
        h = h.permute(1,0,2) #[N*1*D]
        # test = x[torch.arange(x.shape[0]),a1,:].unsqueeze(1)
        # # print(x[0,a1[0],:])
        # # print(test[0])
        xx = F.relu(self.fc1(h))
        '''head1 for item action''' 
        xxx = xx.repeat(1,y.shape[1],1) # [N*K*D]
        state_cat_action = torch.cat((xxx,y),dim=2)
        a_logits = self.fc3(F.relu(self.fc2(state_cat_action))).squeeze(dim=2) #[N*K*1] --> [N*K]
        # print('a_logits', a_logits)
        # print('a_logits shape', a_logits.shape)
        a_prob = F.softmax(a_logits, dim=1) # prob
        # print('a_prob', a_prob)
        # print('a_prob shape', a_prob.shape)
        dist = torch.distributions.Categorical(a_prob) # dist
        a_idx = item_action if item_action is not None else dist.sample() # action: (batch_size,) or (batch_size, k)
        # print('a_idx', a_idx) 
        # print('a_idx shape', a_idx.shape)
        a_entropy = dist.entropy() # action entropy: (batch_size,) or (batch_size, k)
        # print('a_entropy', a_entropy)
        # print('a_entropy shape', a_entropy.shape)
        a_log_prob = dist.log_prob(a_idx.flatten()) # action log prob: (batch_size,) or (batch_size, k)
        # print('a_log_prob', a_log_prob)
        # print('a_log_prob shape', a_log_prob.shape)
        
        '''head2 for pivot action'''
        pivot_logits = self.fc4(xx).squeeze(dim=1)# logits: [N*1*epi_len*1] --> [N*epi_len]
        # print('pivot_logits', pivot_logits)
        # print('pivot_logits shape', pivot_logits.shape)
        dist_masked = CategoricalMasked(logits=pivot_logits, mask = torch.Tensor(pivot_mask).type(torch.bool).to(self.args.device) ) # dist
        pivot_prob = dist_masked.probs # prob
        # print('pivot_prob', pivot_prob)
        # print('pivot_prob shape', pivot_prob.shape)
        pivot_idx = pivot_action if pivot_action is not None else dist_masked.sample() # action
        # print('pivot_idx', pivot_idx)
        # print('pivot_idx shape', pivot_idx.shape)
        pivot_entropy = dist_masked.entropy() # action entropy
        # print('pivot_entropy', pivot_entropy)
        # print('pivot_entropy shape', pivot_entropy.shape)
        pivot_log_prob = dist_masked.log_prob(pivot_idx.flatten()) # action log prob
        # print('pivot_log prob', pivot_log_prob)
        # print('pivot_log prob shape', pivot_log_prob.shape)

        ## print('a_idx',a_idx.shape) (93,1)
        ## print('a_idx.flatten',a_idx.flatten()) (93,)
        
        ## print('act_entropy',act_entropy.shape) #(93,)
        ## print('act_log_prob',act_log_prob.shape) #(93,)
        # assert act_log_prob.shape == a_idx.shape
        return [a_idx,pivot_idx], a_log_prob+pivot_log_prob, a_entropy+pivot_entropy   

class ActorP(nn.Module):
    def __init__(self, num_items, args):
        super(ActorP, self).__init__()
        self.args = args
        self.encoding = nn.Embedding(num_items, args.gcn_hidden)
        self.rnn = nn.GRU(args.gcn_hidden, args.gru_hidden, args.gru_layer, batch_first=True)
        self.fc1 = nn.Linear(args.gru_hidden, args.actor_hidden)
        self.fc2 = nn.Linear(args.actor_hidden+args.gcn_hidden, args.actor_hidden)   #hidden_dim + emb_size
        self.fc3 = nn.Linear(args.actor_hidden,1)
    def transform(self, some_state):
        a[a==0] = 1
    def forward(self, some_state, valid_actions, item_action=None):
        """
        :param x: encode state history [N*L*D]; y: action embedding [N*K*E],
            
            N: batch size, L: seq length, D: embedding size, K: action set length
        :return: action score [N*K]
        """
        # state, candi=  some_state['some_state'], some_state['valid_actions']
        # # print('state', state)
        some_state[some_state==-1] = 0
        # # print('state', state)
        candi = valid_actions
        
        # unppad the state
        # state = self.unpad(state)
        x = self.encoding(some_state[:,1:])# [N*L*E]
        y = self.encoding(candi) # [N*C*E]
        out, h = self.rnn(x)
        h = h.permute(1,0,2) #[N*1*D]
        # test = x[torch.arange(x.shape[0]),a1,:].unsqueeze(1)
        # # print(x[0,a1[0],:])
        # # print(test[0])
        x = F.relu(self.fc1(h))
        x = x.repeat(1,y.shape[1],1) # [N*K*D]
        state_cat_action = torch.cat((x,y),dim=2)
        action_logits = self.fc3(F.relu(self.fc2(state_cat_action))).squeeze(dim=2) #[N*K]
        a_prob = F.softmax(action_logits, dim=1)
        dist = torch.distributions.Categorical(a_prob)
        a_idx = item_action if item_action is not None else dist.sample()
        ## print('a_idx',a_idx.shape) (93,1)
        ## print('a_idx.flatten',a_idx.flatten()) (93,)
        act_entropy = dist.entropy()
        act_log_prob = dist.log_prob(a_idx.flatten())
        ## print('act_entropy',act_entropy.shape) #(93,)
        ## print('act_log_prob',act_log_prob.shape) #(93,)
        # assert act_log_prob.shape == a_idx.shape
        return a_idx, act_log_prob, act_entropy

class Actor1(nn.Module):
    def __init__(self, emb_size, x_dim=50, state_dim=50, hidden_dim=50, layer_num=1):
        super(Actor1, self).__init__()
        self.rnn = nn.GRU(x_dim, state_dim, layer_num, batch_first = True)
        self.fc1 = nn.Linear(state_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim+x_dim, hidden_dim)
        self.fc3 = nn.Linear(hidden_dim,1)
    
    def forward(self, x, l):
        '''
        :param x: encode history [N*L*D]; l: current state length Int
            N: batch size, L: seq length, D: embedding size, K: action set length
        :return: v: action score [N*K]
        '''
        out, h = self.rnn(x)
        h = h.permute(1,0,2) #[N*1*D]
        y = x[:,:l,:] #[N*l*D] 
        x = F.relu(self.fc1(h))
        x = x.repeat(1,y.shape[1],1)
        state_cat_action = torch.cat((x,y),dim=2)
        action_score = self.fc3(F.relu(self.fc2(state_cat_action))).squeeze(dim=2) #[N*K]
        action_prob = F.softmax(action_score, dim=1)
        
        return action_score, action_prob

class Actor2(nn.Module):
    def __init__(self, emb_size, x_dim = 50, state_dim=50, hidden_dim=50, layer_num=1):
        super(Actor2, self).__init__()
        # candi_num = 200
        # emb_size = 50
        # x_dim = 50
        # self.candi_num = candi_num
        self.rnn = nn.GRU(x_dim,state_dim,layer_num,batch_first=True)
        self.fc1 = nn.Linear(state_dim+x_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim+emb_size, hidden_dim)   #hidden_dim + emb_size
        self.fc3 = nn.Linear(hidden_dim,1)
    
    def forward(self, x, y, a1):
        """
        :param x: encode history [N*L*D]; y: action embedding [N*K*E],
            a1: seleted item a1_idx[N*1]
            N: batch size, L: seq length, D: embedding size, K: action set length
        :return: v: action score [N*K]
        """
        
        out, h = self.rnn(x)
        h = h.permute(1,0,2) #[N*1*D]
        test = x[torch.arange(x.shape[0]),a1,:].unsqueeze(1)
        # # print(x[0,a1[0],:])
        # # print(test[0])
        h = torch.cat((test,h),dim=2) #a1是index [N*1*(D+x_D)]
        x = F.relu(self.fc1(h))
        x = x.repeat(1,y.shape[1],1) # [N*K*D]
        state_cat_action = torch.cat((x,y),dim=2)
        action_score = self.fc3(F.relu(self.fc2(state_cat_action))).squeeze(dim=2) #[N*K]
        action_prob = F.softmax(action_score, dim=1)
        
        return action_score, action_prob


class Actor(nn.Module):
    def __init__(self, emb_size, x_dim = 50, state_dim=50, hidden_dim=50, layer_num=1):
        super(Actor, self).__init__()
        # candi_num = 200
        # emb_size = 50
        # x_dim = 50
        # self.candi_num = candi_num
        self.rnn = nn.GRU(x_dim,state_dim,layer_num,batch_first=True)
        self.fc1 = nn.Linear(state_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim+emb_size, hidden_dim)   #hidden_dim + emb_size
        self.fc3 = nn.Linear(hidden_dim,1)
    
    def forward(self, x, y):
        """
        :param x: encode history [N*L*D]; y: action embedding [N*K*D], 
            N: batch size, L: seq length, D: embedding size, K: action set length
        :return: v: action score [N*K]
        """
        
        out, h = self.rnn(x)
        h = h.permute(1,0,2) #[N*1*D]
        x = F.relu(self.fc1(h))
        x = x.repeat(1,y.shape[1],1)
        state_cat_action = torch.cat((x,y),dim=2)
        action_score = self.fc3(F.relu(self.fc2(state_cat_action))).squeeze(dim=2) #[N*K]
        action_prob = F.softmax(action_score, dim=1)
        
        return action_score, action_prob

class Critic(nn.Module):
    def __init__(self,encodingNet, args):
        super(Critic, self).__init__()
        self.args = args
        self.encoding = encodingNet
        self.rnn = nn.GRU(args.gcn_hidden, args.gru_hidden, args.gru_layer, batch_first=True)
        self.fc1 = nn.Linear(args.gru_hidden, args.critic_hidden)
        self.fc2 = nn.Linear(args.critic_hidden, args.critic_hidden)
        self.out = nn.Linear(args.critic_hidden, 1)
    def unpad(self, state):
        if len(state.shape) == 1:
            state = state.reshape(-1, state.shape[0])
        for i in range(state.shape[1]):
            if state[0][i] == -1:
                state = state[:,:i]
                break
        return state
    def forward(self, some_state, valid_actions):
        # state, candi=  some_state['some_state'], some_state['valid_actions']
        # # print('state', state)
        state = some_state.cpu().numpy()
        candi = valid_actions.cpu().numpy()
        
        # unppad the state
        # state = self.unpad(state)
        ## print('state shape',state.shape)
        x = self.encoding(state[:,1:])# [N*L*E]
        ## print('x shape',x.shape)
        # y = self.encoding.embedding(torch.LongTensor(candi).to(self.args.device)) # [N*C*E]
        out, h = self.rnn(x)

        h = h.permute(1,0,2) #[N*1*D]
        v = F.relu(self.fc1(h))
        #v(s)
        value = self.out(F.relu(self.fc2(v))).squeeze(dim=2) #[N*1*1]

        return value

class CriticP(nn.Module):
    def __init__(self,num_items, args):
        super(CriticP, self).__init__()
        self.args = args
        self.encoding = nn.Embedding(num_items, args.gcn_hidden)
        self.rnn = nn.GRU(args.gcn_hidden, args.gru_hidden, args.gru_layer, batch_first=True)
        self.fc1 = nn.Linear(args.gru_hidden, args.critic_hidden)
        self.fc2 = nn.Linear(args.critic_hidden, args.critic_hidden)
        self.out = nn.Linear(args.critic_hidden, 1)
    def unpad(self, state):
        if len(state.shape) == 1:
            state = state.reshape(-1, state.shape[0])
        for i in range(state.shape[1]):
            if state[0][i] == -1:
                state = state[:,:i]
                break
        return state
    def forward(self, some_state, valid_actions):
        # state, candi=  some_state['some_state'], some_state['valid_actions']
        # # print('state', state)
        some_state[some_state==-1] = 0
        # # print('state', state)
        candi = valid_actions
        
        # unppad the state
        # state = self.unpad(state)
        x = self.encoding(some_state[:,1:])# [N*L*E]
        ## print('x shape',x.shape)
        # y = self.encoding.embedding(torch.LongTensor(candi).to(self.args.device)) # [N*C*E]
        out, h = self.rnn(x)

        h = h.permute(1,0,2) #[N*1*D]
        v = F.relu(self.fc1(h))
        #v(s)
        value = self.out(F.relu(self.fc2(v))).squeeze(dim=2) #[N*1*1]

        return value

from torch.distributions.categorical import Categorical
from torch import einsum
from einops import  reduce
from typing import Optional

class CategoricalMasked(Categorical):

    def __init__(self, logits: torch.Tensor, mask: Optional[torch.Tensor] = None):
        self.mask = mask
        # print('mask', mask)
        self.batch, self.nb_action = logits.size()
        # print('batch', self.batch)
        # print('nb_action', self.nb_action)
        if mask is None:
            super(CategoricalMasked, self).__init__(logits=logits)
        else:
            self.mask_value = torch.finfo(logits.dtype).min
            # print('mask_value', self.mask_value)
            logits.masked_fill_(~self.mask, self.mask_value)
            # print('logits', logits)
            super(CategoricalMasked, self).__init__(logits=logits)

    def entropy(self):
        if self.mask is None:
            return super().entropy()
        # Elementwise multiplication
        p_log_p = einsum("ij,ij->ij", self.logits, self.probs)
        # Compute the entropy with possible action only
        p_log_p = torch.where(
            self.mask,
            p_log_p,
            torch.tensor(0, dtype=p_log_p.dtype, device=p_log_p.device),
        )
        return -reduce(p_log_p, "b a -> b", "sum", b=self.batch, a=self.nb_action)  
        
